open Utils
open Loc
open M.Syntax

type token = {
  ocamltype : M.BaseTypes.ocamltype option;
  terminal : M.FrontTypes.terminal;
  alias : M.FrontTypes.alias;
  _attributes : M.FrontTypes.attributes;
}

type tokens = token located list

type state = {
  grammar : M.Syntax.partial_grammar;
  tokens : token located list;
  symbols : string located list;
}

let process_symbols (grammar : partial_grammar) :
    M.FrontTypes.symbol located list =
  (* let symbols = ref [] in *)
  let f = L.flat_map in
  let aliases : (string, string) Hashtbl.t = Hashtbl.create 99 in
  let rec visit_branch (pb : parameterized_branch) =
    f visit_producer pb.pb_producers @ O.to_list pb.pb_prec_annotation
  and visit_producer ((_ide, par, _) : producer) =
    (* _ide is the name bound to the parameter (possibly generated by Menhir), which we ignore for now. *)
    visit_parameter par
  and visit_parameter (par : parameter) =
    match par with
    | ParamVar sym ->
        (* Resolve token aliases *)
        let t_name = Hashtbl.find_opt aliases sym.v in
        [ O.map_or ~default:sym (fun s -> { sym with v = s }) t_name ]
    | ParamApp (sym, pars) -> sym :: f visit_parameter pars
    | ParamAnonymous { p = _; v = branches } -> f visit_branch branches
  and visit_decl ({ p; v } : declaration located) =
    match v with
    | DToken (_, sym, alias, _) ->
        O.iter (fun a -> Hashtbl.add aliases a sym) alias;
        [ locate p sym ]
    | DTokenProperties (sym, _, _) | DStart sym -> [ locate p sym ]
    | DType (_, par) | DOnErrorReduce (par, _) -> visit_parameter par
    | DSymbolAttributes (_, _) | DGrammarAttribute _ | DCode _ | DParameter _ ->
        []
  and visit_parameterized_rule (p : parameterized_rule) =
    (p.pr_nt :: p.pr_parameters) @ f visit_branch p.pr_branches
  in
  let s_decls = f visit_decl grammar.pg_declarations in
  let s_rules = f visit_parameterized_rule grammar.pg_rules in
  s_decls @ s_rules

let load_state_from_partial_grammar (grammar : M.Syntax.partial_grammar) :
    (state, Diagnostic.t list) result =
  let symbols = process_symbols grammar in
  try
    let tokens : tokens =
      List.filter_map
        (function
          | ({
               p;
               v = M.Syntax.DToken (ocamltype, terminal, alias, _attributes);
             } :
              M.Syntax.declaration located) ->
              Some
                { p; v = ({ ocamltype; terminal; alias; _attributes } : token) }
          | _ -> None)
        grammar.pg_declarations
    in
    Ok { grammar; tokens; symbols }
  with exn ->
    let diags =
      match exn with
      | M.ParserAux.ParserError { v = msg; p }
      | M.Lexer.LexerError { v = msg; p } ->
          [
            Diagnostic.create ~message:(`String msg)
              ~range:(Range.of_lexical_positions p)
              ();
          ]
      | M.Parser.Error ->
          [
            Diagnostic.create ~message:(`String "There are syntax errors.")
              ~range:Range.first_line ();
          ]
      | _ -> []
    in
    Error diags

let load_state_from_contents (file_name : string) (file_contents : string) :
    (state, Diagnostic.t list) result =
  M.Main.load_grammar_from_contents 0 file_name file_contents
  |> load_state_from_partial_grammar

let standard_lib =
  Standard.menhir_standard_library_grammar |> load_state_from_partial_grammar
  |> R.get_exn

(** If we are inside a semantic action, we shall suggest the binders declared in
    the current branch *)
let completions_for_action (pos : Position.t) ({ grammar; _ } : state) :
    CompletionItem.t list =
  let comps =
    L.(
      let* rule = grammar.pg_rules in
      let* branch = rule.pr_branches in
      let range =
        Range.of_lexical_positions
        @@
        match branch.pb_action.expr with
        | M.IL.ETextual { p; _ } -> p
        | _ -> branch.pb_position
      in
      if Position.compare_inclusion pos range = `Inside then
        Keywords.position_keywords
        @
        let+ binder, par, _ = branch.pb_producers in
        let binder =
          O.(
            CCString.chop_prefix ~pre:"_" binder.v
            >|= ( ^ ) "$" |> get_or ~default:binder.v)
        in
        CompletionItem.create ~kind:Variable
          ~detail:
            (match par with
            | M.Syntax.ParamVar p | M.Syntax.ParamApp (p, _) -> p.v
            | M.Syntax.ParamAnonymous _ -> "")
          ~label:binder ()
      else [])
  in
  comps

let default_completions ?(docs : (string, string) Hashtbl.t = Hashtbl.create 0)
    ({ tokens; grammar; _ } : state) : CompletionItem.t list =
  let open MenhirSyntax.Syntax in
  CCList.flat_map
    (fun (t : token located) ->
      let comp = CompletionItem.create ~kind:CompletionItemKind.Constant in
      let type_doc =
        O.(
          map
            (fun t ->
              match t with
              | Declared { v; _ } | Inferred v ->
                  `MarkupContent
                    (MarkupContent.create ~kind:Markdown
                       ~value:(Utils.md_fenced v)))
            t.v.ocamltype)
      in

      let ld =
        CompletionItemLabelDetails.create
          ?detail:
            O.(
              t.v.ocamltype >|= fun typ ->
              ": " ^ match typ with Declared { v; _ } | Inferred v -> v)
      in
      comp ~label:t.v.terminal ?documentation:type_doc ~labelDetails:(ld ()) ()
      :: O.(
           t.v.alias
           >|= (fun alias ->
           let description = "alias for " ^ t.v.terminal in
           comp ~label:alias ~detail:description
             ?documentation:type_doc
               (* This is persistent text that sits next to the label.
           The previous ~detail argument won't be shown while scrolling
           if there is ~labelDetails. *)
             ~labelDetails:(ld ~description:t.v.terminal ())
             ())
           |> to_list))
    tokens
  @ List.map
      (fun (rule : parameterized_rule) ->
        let label = rule.pr_nt.v in
        let comp =
          CompletionItem.create ~kind:CompletionItemKind.Function ~label
            ?documentation:
              O.(
                CCHashtbl.get docs label >|= fun doc ->
                `MarkupContent (MarkupContent.create ~kind:Markdown ~value:doc))
            ~labelDetails:
              (CompletionItemLabelDetails.create
                 ~detail:
                   (match rule.pr_parameters with
                   | [] -> ""
                   | _ ->
                       L.to_string ~start:"(" ~stop:")"
                         (fun { p = _; v } -> v)
                         rule.pr_parameters)
                 ())
        in
        comp ())
      grammar.pg_rules

let percent_completions =
  CCHashtbl.map_list
    (fun k doclines ->
      let c =
        CompletionItem.create ~kind:CompletionItemKind.Keyword
          ~documentation:
            (`MarkupContent
               (MarkupContent.create ~kind:Markdown
                  ~value:(CCString.concat "\n\n" doclines)))
      in
      if k = "token_t" then
        c ~label:"%token" ~insertTextFormat:InsertTextFormat.Snippet
          ~insertText:"token <$1> $0"
          ~labelDetails:
            (CompletionItemLabelDetails.create ~detail:" <typexpr>" ())
          ()
      else c ~label:("%" ^ k) ~insertText:k ())
    Keywords.declarations

let standard_lib_completions =
  default_completions standard_lib ~docs:Standard.menhir_standard_library_doc

let document_symbols ({ grammar = { pg_rules; _ }; tokens; _ } : state) :
    DocumentSymbol.t list =
  (* Here we extract a listing of the defined tokens and grammar rules. *)
  CCList.(
    ( tokens >|= fun t ->
      let range = Range.of_lexical_positions t.p in
      DocumentSymbol.create ~kind:SymbolKind.Constant ~name:t.v.terminal ~range
        ~selectionRange:range
        ~detail:(CCOption.get_or ~default:"" t.v.alias)
        () )
    @ ( pg_rules >|= fun t ->
        let range = Range.of_lexical_positions t.pr_nt.p in
        DocumentSymbol.create ~kind:SymbolKind.Function ~name:t.pr_nt.v ~range
          ~selectionRange:range () ))

let symbol_at_position (state : state) (pos : Position.t) :
    (Range.t * string located) option =
  L.find_map
    (fun (s : string located) ->
      let rng = Range.of_lexical_positions s.p in
      let res = Position.compare_inclusion pos rng = `Inside in
      if res then Some (rng, s) else None)
    state.symbols

(** Produce hover information at a particular position. For:
    - token aliases, we display their full name;
    - standard library rules, their documentation; *)
let hover (state : state) (pos : Position.t) =
  let open O in
  let* rng, sym = symbol_at_position state pos in
  (let+ stdlib_doc =
     Hashtbl.find_opt Standard.menhir_standard_library_doc sym.v
   in
   (stdlib_doc, rng))
  <+> L.find_map
        (fun ({ v = t; _ } : token located) ->
          if_
            (fun _ -> t.alias = Some sym.v || t.terminal = sym.v)
            ( O.map_or ~default:""
                (function
                  | M.BaseTypes.Declared { v; _ } | M.BaseTypes.Inferred v ->
                      spr "<%s> " v)
                t.ocamltype
              ^ t.terminal
              |> md_fenced,
              rng ))
        state.tokens

let diagnostics (_state : state) : Lsp.Types.Diagnostic.t list =
  (* let open MenhirSyntax.Syntax in
  List.map
    (function
      | { p; v = { terminal; _ } } ->
          Diagnostic.create ~severity:DiagnosticSeverity.Information
            ~message:(`String (Printf.sprintf "%s is a nice token" terminal))
            ~range:(lsp_range_of_menhir_range p)
            ())
    state.tokens *)
  []

let references (state : state) ~uri ~(pos : Position.t) : Location.t list =
  (let open O in
   let* _sym_range, sym = symbol_at_position state pos in
   (* Is it a token alias? If so, use token's full name. *)
   let sym_name =
     get_or ~default:sym.v
       (L.find_map
          (fun t ->
            let* alias = t.v.alias in
            if_ (fun _ -> alias = sym.v) alias)
          state.tokens)
   in
   epr "Looking for references of %s\n" sym_name;
   Some
     (L.filter_map
        (fun { v; p } ->
          epr "Comparing with %s at %s\n" v
            Range.(show @@ of_lexical_positions p);
          if_
            (fun _ -> v = sym_name)
            (Location.create ~uri ~range:(Range.of_lexical_positions p)))
        state.symbols))
  |> O.to_list |> L.flatten

let definition (state : state) ~uri ~(pos : Position.t) : Locations.t =
  let open O in
  (* Get the symbol under the cursor, if any. *)
  (let* _sym_range, sym = symbol_at_position state pos in
   (* Search for the symbol in the terminals or in the nonterminals. *)
   let+ def =
     L.find_map
       (fun (t : token located) ->
         if_
           (fun _ -> String.equal t.v.terminal sym.v || t.v.alias = Some sym.v)
           (locate t.p t.v.terminal))
       state.tokens
     <+> L.find_map
           (fun (r : M.Syntax.parameterized_rule) ->
             if_ (fun _ -> String.equal r.pr_nt.v sym.v) r.pr_nt)
           state.grammar.pg_rules
   in
   Location.create ~range:(Range.of_lexical_positions def.p) ~uri)
  |> O.to_list
  |> fun locs -> `Location locs

let completions (state : state) ~(pos : Position.t) : CompletionItem.t list =
  match completions_for_action pos state with
  | [] ->
      default_completions state @ standard_lib_completions @ percent_completions
  | l -> l
